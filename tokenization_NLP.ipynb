{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp1rO6tKZyROUmb3L5JKVd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorjoseij/Natural_language_processing/blob/main/tokenization_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDdKUubCOeWR",
        "outputId": "8551ab87-2f28-4037-b1ca-5e98b963e583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Tokenization using Python's NLTK library\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "example_text = \"`"
      ],
      "metadata": {
        "id": "eja8PCSHOqXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_tokenize(example_text))\n",
        "# Word Tokenization using NLTK breaks down text into words and punctuation."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx2g_OksPIfE",
        "outputId": "ffb10eb3-cb6e-4d86-de8f-cdcd72abd43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite', 'the', 'pouring', 'rain', ',', 'vic', 'chose', 'to', 'keep', 'walking', ';', 'he', 'was', \"n't\", 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'üèÉ\\u200d‚ôÇÔ∏èüåß', '.', 'While', 'he', 'was', 'running', ',', 'his', 'mind', 'wandered', 'to', 'his', \"project‚Äî'The\", 'significance', 'of', 'AI', 'in', 'robotics', ',', \"'\", 'which', 'he', 'hadn', '‚Äô', 't', 'started', 'yet', '.', 'But', 'right', 'now', ',', 'all', 'he', 'thought', 'was', ',', \"'Do\", \"n't\", 'stop', '!', \"'\", 'Alas', '!', 'his', 'waterlogged', 'shoes', 'whispered', ',', \"'It\", \"'s\", 'time', 'to', 'pause', '...', \"'\", '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence Tokenization using Python's NLTK library\n",
        "from nltk.tokenize import sent_tokenize\n",
        "print(sent_tokenize(example_text))\n",
        "# Sentence Tokenization breaks text into sentences. Useful for processing at the sentence level, like summarization."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8dSVeThPpCk",
        "outputId": "3aa4f64b-f876-4252-d6cd-31cc3a422fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Despite the pouring rain, vic chose to keep walking; he wasn't going to let a storm dampen his spirits üèÉ\\u200d‚ôÇÔ∏èüåß.\", \"While he was running, his mind wandered to his project‚Äî'The significance of AI in robotics,' which he hadn‚Äôt started yet.\", \"But right now, all he thought was, 'Don't stop!'\", 'Alas!', \"his waterlogged shoes whispered, 'It's time to pause...'.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Punctuation-based Tokenization using Python's NLTK library\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "print( WordPunctTokenizer().tokenize(example_text))\n",
        "# Punctuation-based Tokenizer explicitly separates punctuation from words, treating them as separate tokens."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jblcXGiVPswU",
        "outputId": "37be5a21-21ae-4383-a62c-7fe80c2bccc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite', 'the', 'pouring', 'rain', ',', 'vic', 'chose', 'to', 'keep', 'walking', ';', 'he', 'wasn', \"'\", 't', 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'üèÉ\\u200d‚ôÇÔ∏èüåß.', 'While', 'he', 'was', 'running', ',', 'his', 'mind', 'wandered', 'to', 'his', 'project', \"‚Äî'\", 'The', 'significance', 'of', 'AI', 'in', 'robotics', \",'\", 'which', 'he', 'hadn', '‚Äô', 't', 'started', 'yet', '.', 'But', 'right', 'now', ',', 'all', 'he', 'thought', 'was', ',', \"'\", 'Don', \"'\", 't', 'stop', \"!'\", 'Alas', '!', 'his', 'waterlogged', 'shoes', 'whispered', ',', \"'\", 'It', \"'\", 's', 'time', 'to', 'pause', \"...'.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treebank Word Tokenization using Python's NLTK library\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "print(TreebankWordTokenizer().tokenize(example_text))\n",
        "# Treebank Word Tokenizer uses the Penn Treebank conventions. It's good for tokens that conform to the Treebank standards."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XNPx9pgPv8J",
        "outputId": "35e587b6-6de7-4ce5-f8cc-d15472ed432a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite', 'the', 'pouring', 'rain', ',', 'vic', 'chose', 'to', 'keep', 'walking', ';', 'he', 'was', \"n't\", 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'üèÉ\\u200d‚ôÇÔ∏èüåß.', 'While', 'he', 'was', 'running', ',', 'his', 'mind', 'wandered', 'to', 'his', \"project‚Äî'The\", 'significance', 'of', 'AI', 'in', 'robotics', ',', \"'\", 'which', 'he', 'hadn‚Äôt', 'started', 'yet.', 'But', 'right', 'now', ',', 'all', 'he', 'thought', 'was', ',', \"'Do\", \"n't\", 'stop', '!', \"'\", 'Alas', '!', 'his', 'waterlogged', 'shoes', 'whispered', ',', \"'It\", \"'s\", 'time', 'to', 'pause', '...', \"'\", '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet Tokenizer using Python's NLTK library\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "print(TweetTokenizer().tokenize(example_text))\n",
        "# Tweet Tokenizer is tailored for the nuances of tweets, like hashtags, emoticons, and other internet-slang."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhFEaP5zPzTk",
        "outputId": "cede3d4f-f16a-47bf-e87f-4496261e082a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite', 'the', 'pouring', 'rain', ',', 'vic', 'chose', 'to', 'keep', 'walking', ';', 'he', \"wasn't\", 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'üèÉ\\u200d‚ôÇ', 'Ô∏è', 'üåß', '.', 'While', 'he', 'was', 'running', ',', 'his', 'mind', 'wandered', 'to', 'his', 'project', '‚Äî', \"'\", 'The', 'significance', 'of', 'AI', 'in', 'robotics', ',', \"'\", 'which', 'he', 'hadn', '‚Äô', 't', 'started', 'yet', '.', 'But', 'right', 'now', ',', 'all', 'he', 'thought', 'was', ',', \"'\", \"Don't\", 'stop', '!', \"'\", 'Alas', '!', 'his', 'waterlogged', 'shoes', 'whispered', ',', \"'\", \"It's\", 'time', 'to', 'pause', '...', \"'\", '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Word Expression Tokenizer using Python's NLTK library\n",
        "from nltk.tokenize import MWETokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "mwe_tokenizer = MWETokenizer([('AI', 'in', 'healthcare')])\n",
        "print(mwe_tokenizer.tokenize(word_tokenize(example_text)))\n",
        "# Multi-Word Expression Tokenizer maintains multi-word expressions as single tokens."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q0YwwQFP3Bl",
        "outputId": "b4797941-673f-46a1-fd14-34dbedce4bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite', 'the', 'pouring', 'rain', ',', 'vic', 'chose', 'to', 'keep', 'walking', ';', 'he', 'was', \"n't\", 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'üèÉ\\u200d‚ôÇÔ∏èüåß', '.', 'While', 'he', 'was', 'running', ',', 'his', 'mind', 'wandered', 'to', 'his', \"project‚Äî'The\", 'significance', 'of', 'AI', 'in', 'robotics', ',', \"'\", 'which', 'he', 'hadn', '‚Äô', 't', 'started', 'yet', '.', 'But', 'right', 'now', ',', 'all', 'he', 'thought', 'was', ',', \"'Do\", \"n't\", 'stop', '!', \"'\", 'Alas', '!', 'his', 'waterlogged', 'shoes', 'whispered', ',', \"'It\", \"'s\", 'time', 'to', 'pause', '...', \"'\", '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextBlob Word Tokenize using TextBlob library\n",
        "from textblob import TextBlob\n",
        "print(TextBlob(example_text).words)\n",
        "# TextBlob Word Tokenizer is simple and useful for quick tasks like spell checking and translation within the TextBlob framework."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynMLLmuWP69M",
        "outputId": "9770c601-5663-491d-ce80-d927170025f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite', 'the', 'pouring', 'rain', 'vic', 'chose', 'to', 'keep', 'walking', 'he', 'was', \"n't\", 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'üèÉ\\u200d‚ôÇÔ∏èüåß', 'While', 'he', 'was', 'running', 'his', 'mind', 'wandered', 'to', 'his', \"project‚Äî'The\", 'significance', 'of', 'AI', 'in', 'robotics', 'which', 'he', 'hadn', '‚Äô', 't', 'started', 'yet', 'But', 'right', 'now', 'all', 'he', 'thought', 'was', \"'Do\", \"n't\", 'stop', 'Alas', 'his', 'waterlogged', 'shoes', 'whispered', \"'It\", \"'s\", 'time', 'to', 'pause']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim word tokenizer using Gensim library\n",
        "from gensim.utils import tokenize\n",
        "print(list(tokenize(example_text)))\n",
        "# Gensim is used for unsupervised topic modeling and natural language processing, and its tokenizer is simple but effective."
      ],
      "metadata": {
        "id": "wqV3pSvsQEeq",
        "outputId": "96ccfc13-49a9-4abb-ec10-e9311f74c19f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite', 'the', 'pouring', 'rain', 'vic', 'chose', 'to', 'keep', 'walking', 'he', 'wasn', 't', 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'While', 'he', 'was', 'running', 'his', 'mind', 'wandered', 'to', 'his', 'project', 'The', 'significance', 'of', 'AI', 'in', 'robotics', 'which', 'he', 'hadn', 't', 'started', 'yet', 'But', 'right', 'now', 'all', 'he', 'thought', 'was', 'Don', 't', 'stop', 'Alas', 'his', 'waterlogged', 'shoes', 'whispered', 'It', 's', 'time', 'to', 'pause']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization with Keras\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "print(text_to_word_sequence(example_text))\n",
        "\n",
        "# Keras tokenizer is part of the deep learning library and can be used as part of a neural network pipeline¬†for¬†NLP."
      ],
      "metadata": {
        "id": "c558ZizJQHpo",
        "outputId": "58f83c84-39db-4557-f137-fd3b73d24510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['despite', 'the', 'pouring', 'rain', 'vic', 'chose', 'to', 'keep', 'walking', 'he', \"wasn't\", 'going', 'to', 'let', 'a', 'storm', 'dampen', 'his', 'spirits', 'üèÉ\\u200d‚ôÇÔ∏èüåß', 'while', 'he', 'was', 'running', 'his', 'mind', 'wandered', 'to', 'his', \"project‚Äî'the\", 'significance', 'of', 'ai', 'in', 'robotics', \"'\", 'which', 'he', 'hadn‚Äôt', 'started', 'yet', 'but', 'right', 'now', 'all', 'he', 'thought', 'was', \"'don't\", 'stop', \"'\", 'alas', 'his', 'waterlogged', 'shoes', 'whispered', \"'it's\", 'time', 'to', 'pause', \"'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word and sentence tokenization provide a foundation for sentiment analysis and content categorization.\n",
        "Punctuation-based tokenizer aids in extracting context around specific terms.\n",
        "Treebank Word Tokenizer handles irregularities, crucial for understanding nuanced language.\n",
        "Tweet Tokenizer is essential for processing social media content with hashtags and mentions.\n",
        "Multi-Word Expression Tokenizer captures idiomatic language, enhancing contextual understanding.\n",
        "TextBlob and spaCy tokenizers offer advanced linguistic features for comprehensive NLP tasks.\n",
        "Gensim Word Tokenizer excels in topic modeling applications.\n",
        "Keras Tokenization is essential for preparing text data for deep learning models, beneficial in tasks like text generation.\n"
      ],
      "metadata": {
        "id": "bir_-uFiEvAy"
      }
    }
  ]
}